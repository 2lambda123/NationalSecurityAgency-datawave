package datawave.query.language.analyzers.lucene;

import java.util.HashSet;
import java.util.Set;

import org.apache.lucene.analysis.CharArraySet;
import org.apache.lucene.analysis.LowerCaseFilter;
import org.apache.lucene.analysis.StopFilter;
import org.apache.lucene.analysis.StopwordAnalyzerBase;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.Tokenizer;
import org.apache.lucene.analysis.miscellaneous.SetKeywordMarkerFilter;
import org.apache.lucene.analysis.snowball.SnowballFilter;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.analysis.standard.StandardTokenizer;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.tartarus.snowball.SnowballProgram;

import datawave.query.exceptions.DatawaveFatalQueryException;

/**
 * Similar to {@link StandardAnalyzer}, but the {@code createComponents(String)} method is broken out into overridable methods to support language-specific
 * implementations.
 * <p>
 * Support exists for stop words, stemming, and lemmatization.
 * <p>
 * Note: this class is specifically used for query expansion. It is NOT a replacement for tokenization at ingest time. Care should be taken to ensure that
 * tokens generated by the {@link LanguageAwareAnalyzer}s are a superset of the tokens generated at ingest time.
 */
public abstract class LanguageAwareAnalyzer extends StopwordAnalyzerBase {

    private static final Logger log = LoggerFactory.getLogger(LanguageAwareAnalyzer.class);

    protected boolean stopWordsEnabled = true;
    protected boolean stemExclusionsEnabled = true;
    protected boolean stemmingEnabled = true;
    protected boolean lemmasEnabled = true;
    protected boolean unigrammingEnabled = true;
    protected boolean bigrammingEnabled = true;

    protected CharArraySet stemExclusions;

    // purposefully set-aside variable, used in place of stopwords in StandardAnalyzerBase
    private CharArraySet stopWords;

    public LanguageAwareAnalyzer() {
        this(CharArraySet.EMPTY_SET);
    }

    public LanguageAwareAnalyzer(CharArraySet stopWords) {
        this(stopWords, CharArraySet.EMPTY_SET);
    }

    public LanguageAwareAnalyzer(CharArraySet stopWords, CharArraySet stemExclusions) {
        super(stopWords);
        this.stemExclusions = stemExclusions;
    }

    /**
     * Find alternates to a piece of text
     *
     * @param field
     *            the field
     * @param text
     *            the text
     * @return a set of alternates
     */
    public Set<String> findAlternates(String field, String text) {
        Set<String> tokens = new HashSet<>();

        try (TokenStream tokenStream = getTokenStream(field, text)) {
            tokenStream.reset();

            while (tokenStream.incrementToken()) {
                String token = tokenStream.getAttribute(CharTermAttribute.class).toString();
                log.debug("tok: {}", token);
                if (token != null && !text.equals(token)) {
                    tokens.add(token);
                }
            }

        } catch (Exception e) {
            log.error(e.getMessage());
            throw new DatawaveFatalQueryException(e);
        }
        return tokens;
    }

    /**
     * Wrapper around {@link StandardAnalyzer#tokenStream(String, String)}
     *
     * @param field
     *            the field
     * @param text
     *            the text
     * @return a TokenStream
     */
    public TokenStream getTokenStream(String field, String text) {
        return this.tokenStream(field, text);
    }

    /**
     * Find the best alternate to a piece of text
     *
     * @param field
     *            the field
     * @param text
     *            the text
     * @return the best alternate token
     */
    public String findBestAlternate(String field, String text) {
        Set<String> tokens = findAlternates(field, text);
        if (!tokens.isEmpty()) {
            return tokens.iterator().next();
        }
        return null;
    }

    /**
     * A simple routine that determines if the language matches the provided text
     *
     * @param text
     *            raw text
     * @return true if this language analyzer can be applied to the text
     */
    public abstract boolean matches(String text);

    /**
     * Using EnglishAnalyzer as an example
     *
     * @param fieldName
     *            the field name
     * @return a TokenStreamComponents
     */
    @Override
    protected TokenStreamComponents createComponents(String fieldName) {
        final Tokenizer source = getTokenizer();

        TokenStream result = getBaseFilter(source);

        if (stopWordsEnabled) {
            result = getStopWordFilter(result);
        }

        if (stopWordsEnabled && stopWords != null) {
            result = getStopWordFilter(result);
        }

        if (stemmingEnabled) {
            if (stemExclusionsEnabled) {
                result = getStemExclusions(result);
            }
            result = getStemFilter(result);
        }

        if (lemmasEnabled) {
            result = getLemmatization(result);
        }

        return new TokenStreamComponents(source, result);
    }

    /**
     * Create the initial tokenizer
     * <p>
     * Most languages will use the {@link StandardTokenizer}
     *
     * @return a {@link Tokenizer}
     */
    protected Tokenizer getTokenizer() {
        return new StandardTokenizer();
    }

    /**
     * Create the first filter or set of filters applied to the tokenizer
     * <p>
     * Most languages will use the {@link LowerCaseFilter}
     *
     * @param stream
     *            the TokenStream
     * @return the TokenStream wrapped in a filter or set of filters
     */
    protected TokenStream getBaseFilter(TokenStream stream) {
        return new LowerCaseFilter(stream);
    }

    /**
     * Filters are applied to the token stream when stop words are enabled, in most cases. Some languages require specific types of filters.
     *
     * @param stream
     *            the TokenStream
     * @return the TokenStream wrapped in a filter
     */
    protected TokenStream getStopWordFilter(TokenStream stream) {
        return new StopFilter(stream, getStopWords());
    }

    /**
     * Configure any stem exclusions
     *
     * @param stream
     *            the TokenStream
     * @return the TokenStream wrapped in a filter
     */
    protected TokenStream getStemExclusions(TokenStream stream) {
        return new SetKeywordMarkerFilter(stream, getStemExclusions());
    }

    /**
     * Configure stemming
     *
     * @param stream
     *            the TokenStream
     * @return the TokenStream wrapped in a stemming filter
     */
    protected TokenStream getStemFilter(TokenStream stream) {
        return new SnowballFilter(stream, getStemmer());
    }

    /**
     * Get the language-specific stemmer.
     * <p>
     * Some analyzers use a stemmer, other languages use a stemming filter.
     *
     * @return a Stemmer
     */
    protected SnowballProgram getStemmer() {
        throw new IllegalArgumentException("getStemmer() not supported");
    }

    /**
     * Configure lemmatization.
     * <p>
     * Note: no default implementation is provided by design.
     *
     * @param stream
     *            the token stream
     * @return the token stream
     */
    protected TokenStream getLemmatization(TokenStream stream) {
        // not part of the default implementation
        return stream;
    }

    /**
     * Do not get the {@link StopwordAnalyzerBase#stopwords}, use our own.
     *
     * @return our stop words
     */
    @Override
    public CharArraySet getStopwordSet() {
        return getStopWords();
    }

    public CharArraySet getStopWords() {
        if (stopWords == null) {
            stopWords = getDefaultStopWords();
        }
        return stopWords;
    }

    /**
     * Extending classes should delegate to the appropriate {@link StandardAnalyzer#getStopwordSet()}, or provide a custom set of stopwords
     *
     * @return the default stop words for a language
     */
    public abstract CharArraySet getDefaultStopWords();

    public CharArraySet getStemExclusions() {
        return stemExclusions;
    }

    public void setStopWordsEnabled(boolean stopWordsEnabled) {
        this.stopWordsEnabled = stopWordsEnabled;
    }

    public void setStemExclusionsEnabled(boolean stemExclusionsEnabled) {
        this.stemExclusionsEnabled = stemExclusionsEnabled;
    }

    public void setStemmingEnabled(boolean stemmingEnabled) {
        this.stemmingEnabled = stemmingEnabled;
    }

    public void setLemmasEnabled(boolean lemmasEnabled) {
        this.lemmasEnabled = lemmasEnabled;
    }

    public void setStemExclusions(CharArraySet stemExclusions) {
        this.stemExclusions = stemExclusions;
    }

    public boolean isUnigrammingEnabled() {
        return unigrammingEnabled;
    }

    public void setUnigrammingEnabled(boolean unigrammingEnabled) {
        this.unigrammingEnabled = unigrammingEnabled;
    }

    public boolean isBigrammingEnabled() {
        return bigrammingEnabled;
    }

    public void setBigrammingEnabled(boolean bigrammingEnabled) {
        this.bigrammingEnabled = bigrammingEnabled;
    }
}
